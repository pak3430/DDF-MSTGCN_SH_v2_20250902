#!/usr/bin/env python3
"""
DRT Dashboard ETL Pipeline
ì‘ì„±ì¼: 2025-09-01
ëª©ì : Materialized Views ê°±ì‹  ë° ë°ì´í„° ì§‘ê³„ ìë™í™”

ì‹¤í–‰ ë°©ë²•:
python3 run_etl.py

í™˜ê²½ë³€ìˆ˜:
- DATABASE_URL: PostgreSQL ì—°ê²° ë¬¸ìì—´
- ETL_LOG_LEVEL: ë¡œê·¸ ë ˆë²¨ (DEBUG, INFO, WARNING, ERROR)
"""

import os
import sys
import logging
import asyncio
import asyncpg
from datetime import datetime, timedelta
from typing import Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=getattr(logging, os.getenv('ETL_LOG_LEVEL', 'INFO')),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(f'/tmp/etl_{datetime.now().strftime("%Y%m%d")}.log')
    ]
)
logger = logging.getLogger(__name__)

class DRTETLPipeline:
    """DRT Dashboard ETL íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.db_url = os.getenv('DATABASE_URL', 'postgresql://postgres@localhost:5432/ddf_mstgcn')
        self.connection: Optional[asyncpg.Connection] = None
        
    async def connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            self.connection = await asyncpg.connect(self.db_url)
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    async def disconnect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ"""
        if self.connection:
            await self.connection.close()
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ")
    
    async def check_source_data(self) -> dict:
        """ì†ŒìŠ¤ ë°ì´í„° ìƒíƒœ í™•ì¸"""
        logger.info("ì†ŒìŠ¤ ë°ì´í„° ìƒíƒœ í™•ì¸ ì¤‘...")
        
        stats = {}
        
        # 1. station_passenger_history í…Œì´ë¸” í™•ì¸
        query = """
        SELECT 
            COUNT(*) as total_records,
            COUNT(DISTINCT node_id) as unique_stations,
            COUNT(DISTINCT record_date) as unique_dates,
            MIN(record_date) as earliest_date,
            MAX(record_date) as latest_date
        FROM station_passenger_history;
        """
        result = await self.connection.fetchrow(query)
        stats['passenger_history'] = dict(result)
        
        # 2. spatial_mapping í…Œì´ë¸” í™•ì¸
        query = """
        SELECT 
            COUNT(*) as total_mappings,
            COUNT(*) FILTER (WHERE is_seoul = TRUE) as seoul_stations,
            COUNT(DISTINCT sgg_name) as unique_districts
        FROM spatial_mapping;
        """
        result = await self.connection.fetchrow(query)
        stats['spatial_mapping'] = dict(result)
        
        # 3. bus_stops í…Œì´ë¸” í™•ì¸
        query = """
        SELECT 
            COUNT(*) as total_bus_stops,
            COUNT(*) FILTER (WHERE coordinates_x IS NOT NULL AND coordinates_y IS NOT NULL) as with_coordinates
        FROM bus_stops;
        """
        result = await self.connection.fetchrow(query)
        stats['bus_stops'] = dict(result)
        
        logger.info(f"ì†ŒìŠ¤ ë°ì´í„° ìƒíƒœ: {stats}")
        return stats
    
    async def refresh_materialized_views(self):
        """Materialized Views ê°±ì‹ """
        logger.info("Materialized Views ê°±ì‹  ì‹œì‘...")
        
        try:
            # 1. ê¸°ë³¸ êµí†µ íŒ¨í„´ ê°±ì‹ 
            logger.info("1/4: ì‹œê°„ëŒ€ë³„ êµí†µ íŒ¨í„´ ê°±ì‹ ...")
            await self.connection.execute("REFRESH MATERIALIZED VIEW mv_hourly_traffic_patterns;")
            
            # 2. êµ¬ë³„ ì›”ê°„ êµí†µëŸ‰ ê°±ì‹ 
            logger.info("2/4: êµ¬ë³„ ì›”ê°„ êµí†µëŸ‰ ê°±ì‹ ...")
            await self.connection.execute("REFRESH MATERIALIZED VIEW mv_district_monthly_traffic;")
            
            # 3. ì •ë¥˜ì¥ë³„ ì›”ê°„ êµí†µëŸ‰ ê°±ì‹ 
            logger.info("3/4: ì •ë¥˜ì¥ë³„ ì›”ê°„ êµí†µëŸ‰ ê°±ì‹ ...")
            await self.connection.execute("REFRESH MATERIALIZED VIEW mv_station_monthly_traffic;")
            
            # 4. ì„œìš¸ì‹œ ì „ì²´ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê°±ì‹  (ì˜ì¡´ì„± ìˆìŒ)
            logger.info("4/4: ì„œìš¸ì‹œ ì „ì²´ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê°±ì‹ ...")
            await self.connection.execute("REFRESH MATERIALIZED VIEW mv_seoul_hourly_patterns;")
            
            logger.info("âœ… ëª¨ë“  Materialized Views ê°±ì‹  ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Materialized Views ê°±ì‹  ì‹¤íŒ¨: {e}")
            raise
    
    async def refresh_station_hourly_patterns(self):
        """ì •ë¥˜ì¥ë³„ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê°±ì‹  (ì¶”ê°€ MV)"""
        logger.info("ì •ë¥˜ì¥ë³„ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê°±ì‹ ...")
        
        try:
            await self.connection.execute("SELECT refresh_station_hourly_patterns();")
            logger.info("âœ… ì •ë¥˜ì¥ë³„ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê°±ì‹  ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ì •ë¥˜ì¥ë³„ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê°±ì‹  ì‹¤íŒ¨: {e}")
            raise
    
    async def verify_results(self) -> dict:
        """ê²°ê³¼ ê²€ì¦"""
        logger.info("ê²°ê³¼ ê²€ì¦ ì¤‘...")
        
        verification = {}
        
        try:
            # 1. ê° MVì˜ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
            mvs = [
                'mv_hourly_traffic_patterns',
                'mv_district_monthly_traffic', 
                'mv_station_monthly_traffic',
                'mv_seoul_hourly_patterns',
                'mv_station_hourly_patterns'
            ]
            
            for mv in mvs:
                try:
                    count = await self.connection.fetchval(f"SELECT COUNT(*) FROM {mv};")
                    verification[mv] = {'record_count': count, 'status': 'OK' if count > 0 else 'EMPTY'}
                except Exception as e:
                    verification[mv] = {'record_count': 0, 'status': f'ERROR: {e}'}
            
            # 2. êµ¬ë³„ ë°ì´í„° í™•ì¸ (ë¬¸ì œê°€ ë˜ì—ˆë˜ ë¶€ë¶„)
            query = """
            SELECT 
                COUNT(DISTINCT sgg_name) as district_count,
                COUNT(*) as total_records
            FROM mv_hourly_traffic_patterns 
            WHERE month_date = '2025-07-01';
            """
            result = await self.connection.fetchrow(query)
            verification['district_coverage'] = dict(result)
            
            # 3. ìƒ˜í”Œ êµ¬ë³„ ë°ì´í„° í™•ì¸
            query = """
            SELECT sgg_name, COUNT(*) as record_count
            FROM mv_hourly_traffic_patterns 
            WHERE month_date = '2025-07-01'
            GROUP BY sgg_name
            ORDER BY record_count DESC
            LIMIT 5;
            """
            results = await self.connection.fetch(query)
            verification['top_districts'] = [dict(r) for r in results]
            
            logger.info(f"ê²°ê³¼ ê²€ì¦: {verification}")
            return verification
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise
    
    async def run_etl(self):
        """ì „ì²´ ETL íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ ETL íŒŒì´í”„ë¼ì¸ ì‹œì‘: {start_time}")
        
        try:
            # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            await self.connect()
            
            # 2. ì†ŒìŠ¤ ë°ì´í„° ìƒíƒœ í™•ì¸
            source_stats = await self.check_source_data()
            
            # 3. Materialized Views ê°±ì‹ 
            await self.refresh_materialized_views()
            
            # 4. ì •ë¥˜ì¥ë³„ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê°±ì‹ 
            await self.refresh_station_hourly_patterns()
            
            # 5. ê²°ê³¼ ê²€ì¦
            verification = await self.verify_results()
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            logger.info(f"âœ… ETL íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {end_time}")
            logger.info(f"â±ï¸ ì†Œìš” ì‹œê°„: {duration}")
            
            # 6. ìš”ì•½ ì¶œë ¥
            print("\n" + "="*60)
            print("ğŸ‰ DRT Dashboard ETL íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            print("="*60)
            print(f"ğŸ“Š ì†ŒìŠ¤ ë°ì´í„°: {source_stats['passenger_history']['total_records']:,}ê°œ ë ˆì½”ë“œ")
            print(f"ğŸ¢ ì„œìš¸ì‹œ ì •ë¥˜ì¥: {source_stats['spatial_mapping']['seoul_stations']:,}ê°œ")
            print(f"ğŸ—ºï¸ ìì¹˜êµ¬ ìˆ˜: {source_stats['spatial_mapping']['unique_districts']}ê°œ")
            print(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {source_stats['passenger_history']['earliest_date']} ~ {source_stats['passenger_history']['latest_date']}")
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {duration}")
            print("\nğŸ“ˆ Materialized Views ìƒíƒœ:")
            for mv, stats in verification.items():
                if isinstance(stats, dict) and 'record_count' in stats:
                    status_icon = "âœ…" if stats['status'] == 'OK' else "âŒ"
                    print(f"  {status_icon} {mv}: {stats['record_count']:,}ê°œ ë ˆì½”ë“œ")
            print("="*60)
            
        except Exception as e:
            logger.error(f"âŒ ETL íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            raise
        finally:
            await self.disconnect()

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        etl = DRTETLPipeline()
        await etl.run_etl()
    except KeyboardInterrupt:
        logger.info("âŒ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ETL ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    print("ğŸš€ DRT Dashboard ETL Pipeline Starting...")
    asyncio.run(main())