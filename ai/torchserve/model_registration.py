#!/usr/bin/env python3
"""
TorchServe ëª¨ë¸ ìë™ ë“±ë¡ ìŠ¤í¬ë¦½íŠ¸
ì‹œì‘ ì‹œ .mar íŒŒì¼ë“¤ì„ ìŠ¤ìº”í•˜ì—¬ DBì— ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë“±ë¡
"""
import os
import sys
import time
import json
import logging
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import requests
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelRegistration:
    def __init__(self):
        self.db_config = {
            'host': os.getenv('DB_HOST', 'postgres'),
            'port': int(os.getenv('DB_PORT', 5432)),
            'database': os.getenv('DB_NAME', 'ddf_db'),
            'user': os.getenv('DB_USER', 'ddf_user'),
            'password': os.getenv('DB_PASSWORD', 'ddf_password')
        }
        self.model_store_path = Path('/home/model-server/model-store')
        self.torchserve_host = os.getenv('TORCHSERVE_HOST', 'torchserve')
        self.torchserve_port = int(os.getenv('TORCHSERVE_MANAGEMENT_PORT', 8081))
        self.torchserve_url = f'http://{self.torchserve_host}:{self.torchserve_port}'
        
    def wait_for_db(self, max_retries=30, retry_interval=2):
        """PostgreSQL ì—°ê²° ëŒ€ê¸°"""
        for attempt in range(max_retries):
            try:
                conn = psycopg2.connect(**self.db_config)
                conn.close()
                logger.info("âœ… PostgreSQL connection established")
                return True
            except psycopg2.OperationalError as e:
                logger.info(f"â³ Waiting for PostgreSQL... (attempt {attempt + 1}/{max_retries})")
                time.sleep(retry_interval)
        
        logger.error("âŒ Failed to connect to PostgreSQL after maximum retries")
        return False
    
    def wait_for_torchserve(self, max_retries=30, retry_interval=2):
        """TorchServe ì—°ê²° ëŒ€ê¸°"""
        for attempt in range(max_retries):
            try:
                response = requests.get(f"{self.torchserve_url}/ping", timeout=5)
                if response.status_code == 200:
                    logger.info("âœ… TorchServe connection established")
                    return True
            except requests.RequestException:
                logger.info(f"â³ Waiting for TorchServe... (attempt {attempt + 1}/{max_retries})")
                time.sleep(retry_interval)
        
        logger.error("âŒ Failed to connect to TorchServe after maximum retries")
        return False
    
    def get_torchserve_models(self):
        """TorchServe Management APIì—ì„œ ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        try:
            response = requests.get(f"{self.torchserve_url}/models", timeout=10)
            if response.status_code == 200:
                models = response.json()
                logger.info(f"ğŸ“‹ Found {len(models)} models in TorchServe")
                return models
            else:
                logger.warning(f"âš ï¸ TorchServe models API returned status {response.status_code}")
                return []
        except Exception as e:
            logger.error(f"âŒ Failed to fetch models from TorchServe: {e}")
            return []
    
    def get_model_details(self, model_name):
        """íŠ¹ì • ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        try:
            response = requests.get(f"{self.torchserve_url}/models/{model_name}", timeout=10)
            if response.status_code == 200:
                return response.json()
            return None
        except Exception as e:
            logger.error(f"âŒ Failed to get model details for {model_name}: {e}")
            return None
    
    def get_existing_models(self):
        """DBì—ì„œ ê¸°ì¡´ ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        try:
            with psycopg2.connect(**self.db_config) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    cur.execute("""
                        SELECT model_name, model_version, is_active 
                        FROM model_metadata 
                        ORDER BY created_at DESC
                    """)
                    return cur.fetchall()
        except Exception as e:
            logger.error(f"Failed to fetch existing models: {e}")
            return []
    
    def register_model_from_torchserve(self, model_name, model_version="1.0"):
        """TorchServeì—ì„œ ì‹¤ì œ ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì™€ DBì— ë“±ë¡"""
        try:
            # TorchServeì—ì„œ ëª¨ë¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ
            model_details = self.get_model_details(model_name)
            
            with psycopg2.connect(**self.db_config) as conn:
                with conn.cursor() as cur:
                    # ê¸°ì¡´ ëª¨ë¸ ì¡´ì¬ í™•ì¸
                    cur.execute("""
                        SELECT model_id FROM model_metadata 
                        WHERE model_name = %s AND model_version = %s
                    """, (model_name, model_version))
                    
                    if cur.fetchone():
                        logger.info(f"âš ï¸  Model {model_name} v{model_version} already exists - updating...")
                        # ê¸°ì¡´ ëª¨ë¸ ì—…ë°ì´íŠ¸
                        cur.execute("""
                            UPDATE model_metadata SET
                                deployment_status = %s,
                                updated_at = %s,
                                description = %s
                            WHERE model_name = %s AND model_version = %s
                        """, (
                            'active',
                            datetime.now(),
                            f'Updated from TorchServe at {datetime.now()}',
                            model_name, model_version
                        ))
                        logger.info(f"âœ… Model {model_name} v{model_version} updated")
                        return True
                    
                    # ìƒˆ ëª¨ë¸ ë“±ë¡ (TorchServe ì •ë³´ + ê¸°ë³¸ê°’ ì¡°í•©)
                    cur.execute("""
                        INSERT INTO model_metadata (
                            model_name, model_version, model_type,
                            model_architecture, hyperparameters, normalization_stats,
                            model_path, stats_path, graph_path,
                            is_active, is_validated, deployment_status,
                            description, created_by
                        ) VALUES (
                            %s, %s, 'MST-GCN',
                            %s, %s, %s,
                            %s, %s, %s,
                            %s, true, 'active',
                            %s, 'torchserve-api'
                        )
                    """, (
                        model_name, model_version,
                        json.dumps({
                            "name": "Multi-Scale Temporal Graph Convolutional Network",
                            "num_of_vertices": 957,
                            "in_channels": 4,
                            "features": ["normalized_log_boarding_count", "service_availability", "is_rest_day", "normalized_interval"],
                            "torchserve_details": model_details if model_details else "API query failed"
                        }),
                        json.dumps({
                            "K": 3, "nb_block": 2, "nb_chev_filter": 64,
                            "nb_time_filter": 64, "learning_rate": 0.001
                        }),
                        json.dumps({"mean": 0.1110, "std": 1.1544, "method": "z-score"}),
                        f'/app/ddf_model/{model_name}_model_v1.pt',
                        '/app/ddf_model/stats.npz',
                        '/app/ddf_model/adj_mx.npy',
                        True,  # ì²« ë²ˆì§¸ ëª¨ë¸ì€ í™œì„±í™”
                        f'{model_name.upper()} model registered from TorchServe at {datetime.now()}'
                    ))
                    
                    logger.info(f"âœ… Model {model_name} v{model_version} registered from TorchServe")
                    return True
                    
        except Exception as e:
            logger.error(f"Failed to register model {model_name} from TorchServe: {e}")
            return False
    
    def scan_and_register_models(self):
        """TorchServeì—ì„œ ì‹¤ì œ ë¡œë“œëœ ëª¨ë¸ë“¤ì„ ìŠ¤ìº”í•˜ì—¬ ë“±ë¡"""
        # 1. TorchServeì—ì„œ ì‹¤ì œ ë¡œë“œëœ ëª¨ë¸ë“¤ ì¡°íšŒ
        torchserve_models = self.get_torchserve_models()
        
        if not torchserve_models:
            # TorchServeì—ì„œ ëª¨ë¸ì„ ëª» ê°€ì ¸ì˜¤ë©´ fallbackìœ¼ë¡œ .mar íŒŒì¼ ìŠ¤ìº”
            logger.warning("No models found in TorchServe, falling back to .mar file scan")
            return self.scan_mar_files()
        
        registered_count = 0
        for model_info in torchserve_models:
            # TorchServe APIëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì²˜ë¦¬
            if isinstance(model_info, str):
                model_name = model_info
                model_version = '1.0'  # ê¸°ë³¸ ë²„ì „
            else:
                model_name = model_info.get('modelName', 'unknown')
                model_version = model_info.get('modelVersion', '1.0')
            
            logger.info(f"ğŸ” Processing model: {model_name} (version: {model_version})")
            
            if self.register_model_from_torchserve(model_name, model_version):
                registered_count += 1
        
        logger.info(f"ğŸ“Š Model registration summary: {registered_count} models processed from TorchServe")
        return registered_count > 0
    
    def scan_mar_files(self):
        """Fallback: .mar íŒŒì¼ë“¤ì„ ìŠ¤ìº”í•˜ì—¬ ë“±ë¡"""
        if not self.model_store_path.exists():
            logger.warning(f"Model store path not found: {self.model_store_path}")
            return False
        
        mar_files = list(self.model_store_path.glob("*.mar"))
        if not mar_files:
            logger.warning("No .mar files found in model store")
            return False
        
        registered_count = 0
        for mar_file in mar_files:
            model_name = mar_file.stem  # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
            
            if self.register_model_from_torchserve(model_name):
                registered_count += 1
        
        logger.info(f"ğŸ“Š Fallback registration summary: {registered_count} models from .mar files")
        return registered_count > 0
    
    def create_ready_signal(self):
        """ëª¨ë¸ ë“±ë¡ ì™„ë£Œ ì‹ í˜¸ íŒŒì¼ ìƒì„±"""
        ready_file = Path('/tmp/models_registered')
        ready_file.touch()
        logger.info("ğŸš€ Model registration completed - ready signal created")

def main():
    logger.info("ğŸ”„ Starting enhanced TorchServe model registration...")
    
    registrar = ModelRegistration()
    
    # 1. DB ì—°ê²° ëŒ€ê¸°
    if not registrar.wait_for_db():
        sys.exit(1)
    
    # 2. TorchServe ì—°ê²° ëŒ€ê¸°
    if not registrar.wait_for_torchserve():
        logger.warning("âš ï¸  TorchServe not available, will try fallback registration")
    
    # 3. ëª¨ë¸ ìŠ¤ìº” ë° ë“±ë¡ (TorchServe API ìš°ì„ , .mar íŒŒì¼ fallback)
    if not registrar.scan_and_register_models():
        logger.warning("âš ï¸  No models registered, but continuing...")
    
    # 4. ì™„ë£Œ ì‹ í˜¸ ìƒì„±
    registrar.create_ready_signal()
    
    logger.info("âœ… Enhanced model registration process completed successfully")

if __name__ == "__main__":
    main()